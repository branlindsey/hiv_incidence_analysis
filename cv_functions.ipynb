{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2355 entries, 0 to 2354\n",
      "Data columns (total 38 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   county_code        2355 non-null   int64  \n",
      " 1   COUNTY             2355 non-null   object \n",
      " 2   STATEABBREVIATION  2355 non-null   object \n",
      " 3   YEAR               2355 non-null   int64  \n",
      " 4   AMAT_fac           2355 non-null   float64\n",
      " 5   HIVdiagnoses       2355 non-null   float64\n",
      " 6   HIVprevalence      2355 non-null   float64\n",
      " 7   MH_fac             2355 non-null   float64\n",
      " 8   Med_AMAT_fac       2355 non-null   float64\n",
      " 9   Med_MH_fac         2355 non-null   float64\n",
      " 10  Med_SA_fac         2355 non-null   float64\n",
      " 11  Med_SMAT_fac       2355 non-null   float64\n",
      " 12  Med_TMAT_fac       2355 non-null   float64\n",
      " 13  PLHIV              2355 non-null   float64\n",
      " 14  Population         2355 non-null   float64\n",
      " 15  SA_fac             2355 non-null   float64\n",
      " 16  SMAT_fac           2355 non-null   float64\n",
      " 17  TMAT_fac           2355 non-null   float64\n",
      " 18  drugdeathrate      2355 non-null   float64\n",
      " 19  drugdeathrate_est  2355 non-null   float64\n",
      " 20  drugdeaths         2355 non-null   float64\n",
      " 21  mme_percap         2355 non-null   float64\n",
      " 22  partD30dayrxrate   2288 non-null   float64\n",
      " 23  pctunins           2355 non-null   float64\n",
      " 24  num_SSPs           2355 non-null   float64\n",
      " 25  bup_phys           2355 non-null   float64\n",
      " 26  drugdep            2355 non-null   float64\n",
      " 27  pctunmetneed       2355 non-null   float64\n",
      " 28  nonmedpain         2355 non-null   float64\n",
      " 29  ADULTMEN           2355 non-null   int64  \n",
      " 30  MSM12MTH           2355 non-null   int64  \n",
      " 31  MSM5YEAR           2355 non-null   int64  \n",
      " 32  %msm12month        2355 non-null   float64\n",
      " 33  %msm5yr            2355 non-null   float64\n",
      " 34  unemployment_rate  2355 non-null   float64\n",
      " 35  poverty_rate       2355 non-null   float64\n",
      " 36  household_income   2355 non-null   int64  \n",
      " 37  percent_uninsured  2355 non-null   float64\n",
      "dtypes: float64(30), int64(6), object(2)\n",
      "memory usage: 717.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('forecast_HIV_infections/data/x_train.csv', index_col=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1570e+04, 2.0150e+03, 0.0000e+00, ..., 1.0600e+01, 7.0250e+03,\n",
       "        1.2100e+01],\n",
       "       [1.6013e+04, 2.0150e+03, 0.0000e+00, ..., 1.0800e+01, 9.2580e+03,\n",
       "        1.7600e+01],\n",
       "       [2.0900e+03, 2.0150e+03, 0.0000e+00, ..., 8.0000e+00, 3.5844e+04,\n",
       "        1.4300e+01],\n",
       "       ...,\n",
       "       [1.6039e+04, 2.0150e+03, 0.0000e+00, ..., 1.7000e+01, 9.6820e+03,\n",
       "        1.5100e+01],\n",
       "       [5.0110e+03, 2.0150e+03, 0.0000e+00, ..., 2.9400e+01, 4.7200e+03,\n",
       "        2.0000e+01],\n",
       "       [3.9139e+04, 2.0150e+03, 0.0000e+00, ..., 1.6300e+01, 4.8211e+04,\n",
       "        1.1900e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=['COUNTY','STATEABBREVIATION','partD30dayrxrate']).values\n",
    "y = pd.read_csv('forecast_HIV_infections/data/y_train.csv', index_col=0).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class XyScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Standardize a training set of data along with a vector of targets.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X_scaler = StandardScaler()\n",
    "        self.y_scaler = StandardScaler()\n",
    "        \n",
    "    def fit(self, X, y, *args, **kwargs):\n",
    "        \"\"\"Fit the scaler to data and a target vector.\"\"\"\n",
    "        self.X_scaler.fit(X)\n",
    "        self.y_scaler.fit(y.reshape(-1, 1))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y, *args, **kwargs):\n",
    "        \"\"\"Transform a new set of data and target vector.\"\"\"\n",
    "        return (self.X_scaler.transform(X),\n",
    "                self.y_scaler.transform(y.reshape(-1, 1)).flatten())\n",
    "\n",
    "    def inverse_transform(self, X, y, *args, **kwargs):\n",
    "        \"\"\"Tranform from a scaled representation back to the original scale.\"\"\"\n",
    "        return (self.X_scaler.inverse_transform(X),\n",
    "                self.y_scaler.inverse_transform(y.reshape(-1, 1)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(X, y, model, n_folds=10, random_seed=154, scale=True):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n",
    "    test_cv_errors, train_cv_errors = np.empty(n_folds), np.empty(n_folds)\n",
    "    scaler = XyScaler()\n",
    "\n",
    "    for idx, (train_idx, valid_idx) in enumerate (kf.split(X)):\n",
    "        \n",
    "        if scale:\n",
    "            scaler.fit(X[train_idx], y[train_idx])\n",
    "            std_X_train, std_y_train = scaler.transform(X[train_idx], y[train_idx])\n",
    "            std_X_valid, std_y_valid = scaler.transform(X[valid_idx], y[valid_idx])\n",
    "        else:\n",
    "            std_X_train, std_y_train = X[train_idx], y[train_idx]\n",
    "            std_X_valid, std_y_valid = X[valid_idx], y[valid_idx]\n",
    "            \n",
    "        model.fit(std_X_train,std_y_train)\n",
    "        y_train_pred = model.predict(std_X_train)\n",
    "        y_test_pred = model.predict(std_X_valid)\n",
    "        \n",
    "        train_cv_errors[idx] = mean_squared_error(std_y_train, y_train_pred)\n",
    "        test_cv_errors[idx] = mean_squared_error(std_y_valid, y_test_pred)\n",
    "\n",
    "    return train_cv_errors, test_cv_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_at_various_alphas(X, y, model, alphas, n_folds=10, **kwargs):\n",
    "    \n",
    "    cv_errors_train = np.empty(shape=(n_folds, len(alphas)))\n",
    "    cv_errors_test = np.empty(shape=(n_folds, len(alphas)))\n",
    "    \n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        train_cv_errors, test_cv_errors = cross_val(X, y, model(alpha=alpha), n_folds=n_folds)\n",
    "        cv_errors_train[:,idx] = train_cv_errors\n",
    "        cv_errors_test[:,idx] = test_cv_errors\n",
    "        \n",
    "    return cv_errors_train, cv_errors_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "mse_train, mse_test = cross_val(X, y, model, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255.4840547 , 258.48507275, 256.89610909, 253.67174044,\n",
       "       251.05565773, 252.39365854, 256.81677787, 237.06446542,\n",
       "        36.9421193 , 252.72960526])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "mse_train, mse_test = cross_val(X, y, model, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70209315, 0.69962173, 0.70394835, 0.69906187, 0.68531315,\n",
       "       0.69512365, 0.69589307, 0.6494347 , 0.41769809, 0.69220799])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(alpha=0.5)\n",
    "mse_train, mse_test = cross_val(X, y, model, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70250837, 0.69992407, 0.70437074, 0.69942061, 0.68582102,\n",
       "       0.69556185, 0.69622042, 0.64995537, 0.41796317, 0.69252962])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1,10,100,100,1000,10000]\n",
    "mse_train, mse_test = train_at_various_alphas(X, y, Ridge, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66462778, 0.67105382, 0.72921933, 0.72921933, 0.80469303,\n",
       "       0.90129752])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gal)",
   "language": "python",
   "name": "gal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
